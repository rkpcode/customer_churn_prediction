{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008b0930",
   "metadata": {},
   "source": [
    "# üîß Feature Engineering - E-commerce Customer Churn\n",
    "\n",
    "**Philosophy:** Restraint > Complexity (5.6k dataset)  \n",
    "**Approach:** Phased (Baseline ‚Üí Controlled ‚Üí Experimental)  \n",
    "**Goal:** 15-18 production-safe features\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Plan Overview\n",
    "\n",
    "**Phase 1 (MANDATORY):** Baseline features + missing flags (15 features)  \n",
    "**Phase 2 (CONTROLLED):** Add 2-3 features one at a time  \n",
    "**Phase 3 (EXPERIMENTAL):** Optional composite features\n",
    "\n",
    "**Critical Rules:**\n",
    "- ‚úì Train-test split FIRST\n",
    "- ‚úì Fit on train, apply to test\n",
    "- ‚úì No data leakage\n",
    "- ‚úì Keep features NUMERIC (no binning)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb715b9",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f145f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584827b",
   "metadata": {},
   "source": [
    "## üì• Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e24afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/raw/ecommerce_churn.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nChurn Distribution:\")\n",
    "print(df['Churn'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a50c56",
   "metadata": {},
   "source": [
    "## üîç Step 3: Missing Values Analysis\n",
    "\n",
    "**Strategy:**\n",
    "- Median imputation for numerical\n",
    "- Create missing flags (signal value)\n",
    "- Mode imputation for categorical\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL:** We'll fit imputers AFTER train-test split to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02516ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing_Count': missing, 'Missing_%': missing_pct})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Identify columns with missing values\n",
    "numerical_missing = ['Tenure', 'HourSpendOnApp', 'OrderCount', 'DaySinceLastOrder', \n",
    "                     'OrderAmountHikeFromlastYear', 'CouponUsed']\n",
    "print(f\"\\nNumerical columns with missing values: {numerical_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42779b50",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Step 4: Train-Test Split (BEFORE Feature Engineering)\n",
    "\n",
    "**‚ö†Ô∏è CRITICAL STEP:**  \n",
    "Split data FIRST to prevent train-test contamination.\n",
    "\n",
    "**Strategy:**\n",
    "- Stratified split (preserve churn ratio)\n",
    "- 80-20 split\n",
    "- Random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a21459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(['Churn', 'CustomerID'], axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTrain churn rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test churn rate: {y_test.mean()*100:.2f}%\")\n",
    "\n",
    "# Store original indices\n",
    "train_idx = X_train.index\n",
    "test_idx = X_test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01078f53",
   "metadata": {},
   "source": [
    "## üîß PHASE 1: Baseline Feature Engineering\n",
    "\n",
    "### Step 5a: Handle Missing Values\n",
    "\n",
    "**Approach:**\n",
    "1. Create missing flags (fit on train)\n",
    "2. Median imputation for numerical (fit on train)\n",
    "3. Mode imputation for categorical (fit on train)\n",
    "\n",
    "**‚ö†Ô∏è Fit on TRAIN only, apply to BOTH train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies to avoid modifying originals\n",
    "X_train_fe = X_train.copy()\n",
    "X_test_fe = X_test.copy()\n",
    "\n",
    "# 1. Create missing flags (BEFORE imputation)\n",
    "for col in numerical_missing:\n",
    "    if col in X_train_fe.columns:\n",
    "        # Fit on train\n",
    "        X_train_fe[f'{col}_was_missing'] = X_train_fe[col].isnull().astype(int)\n",
    "        # Apply to test\n",
    "        X_test_fe[f'{col}_was_missing'] = X_test_fe[col].isnull().astype(int)\n",
    "\n",
    "print(\"Missing flags created:\")\n",
    "missing_flag_cols = [col for col in X_train_fe.columns if '_was_missing' in col]\n",
    "print(missing_flag_cols)\n",
    "\n",
    "# 2. Median imputation for numerical\n",
    "for col in numerical_missing:\n",
    "    if col in X_train_fe.columns:\n",
    "        # Fit on train\n",
    "        median_val = X_train_fe[col].median()\n",
    "        # Apply to both\n",
    "        X_train_fe[col].fillna(median_val, inplace=True)\n",
    "        X_test_fe[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Imputed {col} with median: {median_val:.2f}\")\n",
    "\n",
    "# 3. Mode imputation for categorical\n",
    "categorical_cols = X_train_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    if X_train_fe[col].isnull().sum() > 0:\n",
    "        # Fit on train\n",
    "        mode_val = X_train_fe[col].mode()[0]\n",
    "        # Apply to both\n",
    "        X_train_fe[col].fillna(mode_val, inplace=True)\n",
    "        X_test_fe[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"Imputed {col} with mode: {mode_val}\")\n",
    "\n",
    "# Verify no missing values\n",
    "print(f\"\\nTrain missing values: {X_train_fe.isnull().sum().sum()}\")\n",
    "print(f\"Test missing values: {X_test_fe.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac90ca",
   "metadata": {},
   "source": [
    "### Step 5b: Encode Categorical Features\n",
    "\n",
    "**Approach:** Label Encoding (tree-based models handle this well)\n",
    "\n",
    "**‚ö†Ô∏è Fit on TRAIN, apply to TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a966a1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "categorical_cols = X_train_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on train\n",
    "    X_train_fe[col] = le.fit_transform(X_train_fe[col])\n",
    "    # Apply to test (handle unseen categories)\n",
    "    X_test_fe[col] = X_test_fe[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "    label_encoders[col] = le\n",
    "    print(f\"Encoded {col}: {len(le.classes_)} categories\")\n",
    "\n",
    "print(f\"\\nTotal categorical features encoded: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc40455a",
   "metadata": {},
   "source": [
    "### Phase 1 Summary: Baseline Features\n",
    "\n",
    "**Features Created:**\n",
    "- Original features: 18 (after dropping CustomerID, Churn)\n",
    "- Missing flags: 6\n",
    "- **Total Phase 1: 24 features**\n",
    "\n",
    "**Next:** Phase 2 will add 2-3 controlled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: BASELINE FEATURES COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTrain shape: {X_train_fe.shape}\")\n",
    "print(f\"Test shape: {X_test_fe.shape}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "print(list(X_train_fe.columns))\n",
    "\n",
    "# Save Phase 1 features for baseline model\n",
    "X_train_phase1 = X_train_fe.copy()\n",
    "X_test_phase1 = X_test_fe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bec62",
   "metadata": {},
   "source": [
    "## üîß PHASE 2: Controlled Feature Addition\n",
    "\n",
    "**Strategy:** Add features ONE AT A TIME, measure impact\n",
    "\n",
    "### Step 6a: Order Frequency\n",
    "\n",
    "**Business Logic:** Frequent buyers = loyal customers  \n",
    "**Leakage Risk:** Low (historical behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75edbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order_frequency (NUMERIC, not categorical)\n",
    "X_train_fe['order_frequency'] = X_train_fe['OrderCount'] / (X_train_fe['Tenure'] + 1)\n",
    "X_test_fe['order_frequency'] = X_test_fe['OrderCount'] / (X_test_fe['Tenure'] + 1)\n",
    "\n",
    "print(\"Order Frequency Statistics (Train):\")\n",
    "print(X_train_fe['order_frequency'].describe())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(X_train_fe[y_train==0]['order_frequency'], bins=30, alpha=0.6, label='Not Churned', color='green')\n",
    "plt.hist(X_train_fe[y_train==1]['order_frequency'], bins=30, alpha=0.6, label='Churned', color='red')\n",
    "plt.xlabel('Order Frequency (orders/month)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Order Frequency Distribution by Churn')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "pd.DataFrame({'Churn': y_train, 'OrderFreq': X_train_fe['order_frequency']}).boxplot(\n",
    "    column='OrderFreq', by='Churn')\n",
    "plt.title('Order Frequency vs Churn')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCorrelation with Churn: {X_train_fe['order_frequency'].corr(y_train):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84180d09",
   "metadata": {},
   "source": [
    "### Step 6b: Complaint Rate\n",
    "\n",
    "**Business Logic:** Complaints indicate dissatisfaction  \n",
    "**‚ö†Ô∏è Leakage Risk:** MODERATE (complaints may be post-churn signal)\n",
    "\n",
    "**Decision:** Include but DOCUMENT leakage risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complaint_rate\n",
    "X_train_fe['complaint_rate'] = X_train_fe['Complain'] / (X_train_fe['OrderCount'] + 1)\n",
    "X_test_fe['complaint_rate'] = X_test_fe['Complain'] / (X_test_fe['OrderCount'] + 1)\n",
    "\n",
    "print(\"Complaint Rate Statistics (Train):\")\n",
    "print(X_train_fe['complaint_rate'].describe())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(X_train_fe[y_train==0]['complaint_rate'], bins=30, alpha=0.6, label='Not Churned', color='green')\n",
    "plt.hist(X_train_fe[y_train==1]['complaint_rate'], bins=30, alpha=0.6, label='Churned', color='red')\n",
    "plt.xlabel('Complaint Rate (complaints/order)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Complaint Rate Distribution by Churn')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "pd.DataFrame({'Churn': y_train, 'ComplaintRate': X_train_fe['complaint_rate']}).boxplot(\n",
    "    column='ComplaintRate', by='Churn')\n",
    "plt.title('Complaint Rate vs Churn')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCorrelation with Churn: {X_train_fe['complaint_rate'].corr(y_train):.3f}\")\n",
    "print(\"\\n‚ö†Ô∏è LEAKAGE WARNING: Monitor this feature's importance in model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172826fa",
   "metadata": {},
   "source": [
    "### Phase 2 Summary: Controlled Features\n",
    "\n",
    "**Features Added:**\n",
    "- order_frequency (NUMERIC)\n",
    "- complaint_rate (NUMERIC, ‚ö†Ô∏è leakage risk)\n",
    "\n",
    "**Total after Phase 2: 26 features**\n",
    "\n",
    "**Decision:** These will be evaluated in baseline model. Keep if importance > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2790bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: CONTROLLED FEATURES COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTrain shape: {X_train_fe.shape}\")\n",
    "print(f\"Test shape: {X_test_fe.shape}\")\n",
    "\n",
    "# Save Phase 2 features\n",
    "X_train_phase2 = X_train_fe.copy()\n",
    "X_test_phase2 = X_test_fe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d5ef8",
   "metadata": {},
   "source": [
    "## üîß PHASE 3: Experimental Features (OPTIONAL)\n",
    "\n",
    "**‚ö†Ô∏è These are NOT for baseline model**\n",
    "\n",
    "### Step 7a: Engagement Score (EXPERIMENTAL)\n",
    "\n",
    "**Concept:** Composite metric combining tenure and orders  \n",
    "**‚ö†Ô∏è Issues:** Reduces interpretability, may not improve over raw features\n",
    "\n",
    "**Decision:** Create but DON'T use in baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fca503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize components\n",
    "scaler_tenure = MinMaxScaler()\n",
    "scaler_orders = MinMaxScaler()\n",
    "\n",
    "# Fit on train, apply to both\n",
    "X_train_fe['tenure_norm'] = scaler_tenure.fit_transform(X_train_fe[['Tenure']])\n",
    "X_test_fe['tenure_norm'] = scaler_tenure.transform(X_test_fe[['Tenure']])\n",
    "\n",
    "X_train_fe['orders_norm'] = scaler_orders.fit_transform(X_train_fe[['OrderCount']])\n",
    "X_test_fe['orders_norm'] = scaler_orders.transform(X_test_fe[['OrderCount']])\n",
    "\n",
    "# Simple engagement score (NO satisfaction - leakage risk)\n",
    "X_train_fe['engagement_score'] = 0.5 * X_train_fe['tenure_norm'] + 0.5 * X_train_fe['orders_norm']\n",
    "X_test_fe['engagement_score'] = 0.5 * X_test_fe['tenure_norm'] + 0.5 * X_test_fe['orders_norm']\n",
    "\n",
    "print(\"Engagement Score Statistics (Train):\")\n",
    "print(X_train_fe['engagement_score'].describe())\n",
    "print(f\"\\nCorrelation with Churn: {X_train_fe['engagement_score'].corr(y_train):.3f}\")\n",
    "print(\"\\n‚ö†Ô∏è EXPERIMENTAL: Compare model with/without this feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e248c77",
   "metadata": {},
   "source": [
    "### Step 7b: CLV Proxy (EXPERIMENTAL)\n",
    "\n",
    "**Concept:** Rough customer lifetime value estimate  \n",
    "**‚ö†Ô∏è Issues:** Cashback ‚â† revenue, tenure appears twice, amplifies noise\n",
    "\n",
    "**Positioning:** \"Rough heuristic for prioritization, not final modeling\"\n",
    "\n",
    "**Decision:** Create but DON'T use in baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLV Proxy = Tenure √ó OrderFrequency √ó Cashback\n",
    "X_train_fe['clv_proxy'] = (\n",
    "    X_train_fe['Tenure'] * \n",
    "    X_train_fe['order_frequency'] * \n",
    "    X_train_fe['CashbackAmount']\n",
    ")\n",
    "\n",
    "X_test_fe['clv_proxy'] = (\n",
    "    X_test_fe['Tenure'] * \n",
    "    X_test_fe['order_frequency'] * \n",
    "    X_test_fe['CashbackAmount']\n",
    ")\n",
    "\n",
    "print(\"CLV Proxy Statistics (Train):\")\n",
    "print(X_train_fe['clv_proxy'].describe())\n",
    "print(f\"\\nCorrelation with Churn: {X_train_fe['clv_proxy'].corr(y_train):.3f}\")\n",
    "print(\"\\n‚ö†Ô∏è EXPERIMENTAL: Weak proxy, use with caution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1613a579",
   "metadata": {},
   "source": [
    "## ‚úÖ Feature Engineering Complete\n",
    "\n",
    "### Final Feature Sets\n",
    "\n",
    "**Phase 1 (Baseline):** 24 features  \n",
    "- Original: 18\n",
    "- Missing flags: 6\n",
    "\n",
    "**Phase 2 (Controlled):** +2 features  \n",
    "- order_frequency\n",
    "- complaint_rate (‚ö†Ô∏è leakage risk)\n",
    "\n",
    "**Phase 3 (Experimental):** +5 features  \n",
    "- tenure_norm, orders_norm, engagement_score\n",
    "- clv_proxy\n",
    "\n",
    "**Total Available:** 31 features\n",
    "\n",
    "**For Baseline Model:** Use Phase 1 + Phase 2 = **26 features**  \n",
    "**After Feature Selection:** Target **15-18 features**\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. ‚úì Feature engineering complete\n",
    "2. ‚Üí Train baseline model (Phase 1 + Phase 2 features)\n",
    "3. ‚Üí Feature importance analysis\n",
    "4. ‚Üí Remove low-importance features (< 0.01)\n",
    "5. ‚Üí Final model with 15-18 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e80943",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nPhase 1 (Baseline): {X_train_phase1.shape[1]} features\")\n",
    "print(f\"Phase 2 (Controlled): {X_train_phase2.shape[1]} features\")\n",
    "print(f\"Phase 3 (All features): {X_train_fe.shape[1]} features\")\n",
    "\n",
    "print(f\"\\n‚úì Train set: {X_train_fe.shape}\")\n",
    "print(f\"‚úì Test set: {X_test_fe.shape}\")\n",
    "print(f\"‚úì No missing values\")\n",
    "print(f\"‚úì No data leakage (fit on train, apply to test)\")\n",
    "\n",
    "print(\"\\nüìä Ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c785f3",
   "metadata": {},
   "source": [
    "## üíæ Save Processed Data\n",
    "\n",
    "Save different feature sets for modeling experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processed data directory\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save Phase 1 (Baseline)\n",
    "X_train_phase1.to_csv('../data/processed/X_train_phase1.csv', index=False)\n",
    "X_test_phase1.to_csv('../data/processed/X_test_phase1.csv', index=False)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "# Save Phase 2 (Baseline + Controlled)\n",
    "X_train_phase2.to_csv('../data/processed/X_train_phase2.csv', index=False)\n",
    "X_test_phase2.to_csv('../data/processed/X_test_phase2.csv', index=False)\n",
    "\n",
    "# Save Phase 3 (All features)\n",
    "X_train_fe.to_csv('../data/processed/X_train_all.csv', index=False)\n",
    "X_test_fe.to_csv('../data/processed/X_test_all.csv', index=False)\n",
    "\n",
    "print(\"‚úì Saved processed data to data/processed/\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - X_train_phase1.csv (baseline)\")\n",
    "print(\"  - X_train_phase2.csv (baseline + controlled)\")\n",
    "print(\"  - X_train_all.csv (all features)\")\n",
    "print(\"  - y_train.csv, y_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
