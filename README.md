# ğŸš€ E-commerce Customer Churn Prediction

**Production-Grade MLOps Implementation** | XGBoost Â· CatBoost Â· LightGBM Â· MLflow Â· DVC Â· FastAPI

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104%2B-green)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-2.9%2B-orange)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-3.30%2B-purple)](https://dvc.org/)

---

## ğŸ¯ Project Overview

A **brutally honest, industry-standard** machine learning system for predicting e-commerce customer churn. This project uses **Gradient Boosted Trees** (XGBoost, CatBoost, LightGBM) instead of unnecessary deep learning because churn prediction is a **tabular data problem**.

### Why This Tech Stack?

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Models** | XGBoost/CatBoost/LightGBM | Faster & more accurate than deep learning for tabular data |
| **Experiment Tracking** | MLflow | Track every experiment, compare models, manage model registry |
| **Data Versioning** | DVC | Version control for datasets (Git for data) |
| **API** | FastAPI | Modern, fast, automatic Swagger docs (Flask is outdated) |
| **Monitoring** | Evidently AI | Detect data drift and model degradation |
| **Deployment** | Docker | "Works on my machine" is not an excuse |

---

## ğŸ“Š Dataset

**Source:** [Kaggle - E-commerce Customer Churn](https://www.kaggle.com/datasets/ankitverma2010/ecommerce-customer-churn-analysis-and-prediction) by Ankit Verma

**Features:**
- **Customer Demographics:** Gender, Marital Status, City Tier
- **Behavioral Metrics:** Tenure, Order Count, Days Since Last Order
- **Engagement:** Hours on App, Satisfaction Score, Complaints
- **Financial:** Cashback Amount, Coupon Usage, Order Amount Hike

---

## ğŸ—ï¸ Project Structure

```
ecommerce_customer_churn/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ fastapi_app.py          # FastAPI application
â”‚   â””â”€â”€ streamlit_app.py         # Streamlit dashboard
â”œâ”€â”€ src/ecommerce_customer_churn/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py       # Kaggle API integration
â”‚   â”‚   â”œâ”€â”€ data_transformation.py  # Feature engineering + SMOTE
â”‚   â”‚   â”œâ”€â”€ model_trainer.py        # XGBoost/CatBoost/LightGBM training
â”‚   â”‚   â”œâ”€â”€ model_evalution.py      # Comprehensive evaluation
â”‚   â”‚   â””â”€â”€ model_monitoring.py     # Evidently AI drift detection
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ training_pipeline.py    # End-to-end training
â”‚   â”‚   â””â”€â”€ prediction_pipeline.py  # Inference pipeline
â”‚   â”œâ”€â”€ exception.py                # Custom exception handling
â”‚   â”œâ”€â”€ logger.py                   # Professional logging (loguru)
â”‚   â””â”€â”€ utils.py                    # Helper functions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw data (tracked by DVC)
â”‚   â””â”€â”€ processed/              # Processed data
â”œâ”€â”€ models/                     # Trained models
â”œâ”€â”€ artifacts/                  # Plots, reports, preprocessors
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ params.yaml                 # Centralized configuration
â”œâ”€â”€ dvc.yaml                    # DVC pipeline definition
â”œâ”€â”€ requirements.txt            # Production dependencies
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ Dockerfile                  # Docker configuration
â””â”€â”€ run_pipeline.py             # Training entry point
```

---

## ğŸš€ Quick Start

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/ecommerce_customer_churn.git
cd ecommerce_customer_churn
```

### 2. Setup Environment

```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure Kaggle API

```bash
# Create .kaggle directory
mkdir ~/.kaggle

# Copy your kaggle.json
cp kaggle.json ~/.kaggle/

# Set permissions (Linux/Mac)
chmod 600 ~/.kaggle/kaggle.json
```

### 4. Train Model

```bash
python run_pipeline.py
```

This will:
- âœ… Download data from Kaggle
- âœ… Perform feature engineering (RFM features, engagement scores)
- âœ… Handle class imbalance with SMOTE
- âœ… Train XGBoost, CatBoost, and LightGBM
- âœ… Log experiments to MLflow
- âœ… Save best model based on ROC-AUC
- âœ… Generate evaluation plots (confusion matrix, ROC curve, SHAP values)

### 5. View MLflow Experiments

```bash
mlflow ui
```

Open http://localhost:5000 to compare model runs.

### 6. Run FastAPI Server

```bash
uvicorn app.fastapi_app:app --reload
```

Open http://localhost:8000/docs for Swagger UI.

### 7. Run Streamlit Dashboard

```bash
streamlit run app/streamlit_app.py
```

---

## ğŸ”§ MLOps Features

### Experiment Tracking (MLflow)

```python
# Automatically logs:
- Model parameters
- Evaluation metrics (ROC-AUC, F1, Precision, Recall)
- Feature importance
- Model artifacts
- SHAP values
```

### Data Versioning (DVC)

```bash
# Initialize DVC
dvc init

# Add remote storage (DagsHub)
dvc remote add -d origin https://dagshub.com/username/ecommerce_customer_churn.dvc

# Track data
dvc add data/raw/ecommerce_churn.csv
git add data/raw/ecommerce_churn.csv.dvc
git commit -m "Track raw data"

# Push data to remote
dvc push
```

### Model Monitoring (Evidently AI)

```python
# Detect data drift
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

report = Report(metrics=[DataDriftPreset()])
report.run(reference_data=train_df, current_data=new_data)
report.save_html("reports/drift_report.html")
```

---

## ğŸ“¡ API Usage

### Single Prediction

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Tenure": 10,
    "CityTier": 1,
    "WarehouseToHome": 15.0,
    "HourSpendOnApp": 3.0,
    "NumberOfDeviceRegistered": 3,
    "SatisfactionScore": 3,
    "NumberOfAddress": 2,
    "Complain": 0,
    "OrderAmountHikeFromlastYear": 15.0,
    "CouponUsed": 5,
    "OrderCount": 10,
    "DaySinceLastOrder": 5,
    "CashbackAmount": 150.0,
    "PreferredLoginDevice": "Mobile Phone",
    "PreferredPaymentMode": "Debit Card",
    "Gender": "Male",
    "PreferedOrderCat": "Laptop & Accessory",
    "MaritalStatus": "Single"
  }'
```

### Batch Prediction

```bash
curl -X POST "http://localhost:8000/predict_csv" \
  -F "file=@customers.csv"
```

---

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t ecommerce-churn-api .

# Run container
docker run -p 8000:8000 ecommerce-churn-api
```

---

## ğŸ“ˆ Model Performance

| Model | ROC-AUC | F1-Score | Precision | Recall |
|-------|---------|----------|-----------|--------|
| XGBoost | 0.XX | 0.XX | 0.XX | 0.XX |
| CatBoost | 0.XX | 0.XX | 0.XX | 0.XX |
| LightGBM | 0.XX | 0.XX | 0.XX | 0.XX |

*(Run training to populate metrics)*

---

## ğŸ› ï¸ Tech Stack Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRODUCTION-GRADE ML STACK                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Ingestion    â†’ Kaggle API             â”‚
â”‚  Feature Eng       â†’ RFM, Engagement Score  â”‚
â”‚  Class Imbalance   â†’ SMOTE                  â”‚
â”‚  Models            â†’ XGBoost/CatBoost/LGBM  â”‚
â”‚  Tracking          â†’ MLflow                 â”‚
â”‚  Versioning        â†’ DVC + Git              â”‚
â”‚  API               â†’ FastAPI                â”‚
â”‚  Frontend          â†’ Streamlit              â”‚
â”‚  Monitoring        â†’ Evidently AI           â”‚
â”‚  Deployment        â†’ Docker                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤ Contributing

This is a portfolio project, but suggestions are welcome!

---

## ğŸ“ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

**rkpcode**

---

## ğŸ“ Learning Resources

- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [DVC Get Started](https://dvc.org/doc/start)
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)

---

**âš ï¸ Remember:** Churn prediction is a **tabular data problem**. Don't use deep learning just because it sounds cool. Gradient Boosting is faster, more accurate, and requires less data.
#   c u s t o m e r _ c h u r n _ p r e d i c t i o n  
 